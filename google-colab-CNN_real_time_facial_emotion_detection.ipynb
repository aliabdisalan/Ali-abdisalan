{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7xme3hp2vxF"
   },
   "source": [
    "**This code implements a deeep learning workflow for Real-Time Emotion Recognition System Using Facial Expressions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-1GXOZFHe0d"
   },
   "source": [
    "Install required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_CPfTB5ispIf",
    "outputId": "65544bc8-090c-4635-8649-4c8a90b98558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\omard\\anaconda3\\lib\\site-packages (3.8.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDvvzPGsspIh",
    "outputId": "57f284e0-a432-4c35-de23-8d3b61812af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\omard\\anaconda3\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\omard\\anaconda3\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\omard\\anaconda3\\lib\\site-packages (from keras) (1.24.3)\n",
      "Requirement already satisfied: rich in c:\\users\\omard\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\omard\\anaconda3\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\omard\\anaconda3\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\omard\\anaconda3\\lib\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\omard\\anaconda3\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from optree->keras) (4.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZXzy6jnspIi",
    "outputId": "316cb985-2a3f-4644-819d-3171ac09c909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\omard\\anaconda3\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\omard\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\omard\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\omard\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ymdw9FbEspIj",
    "outputId": "8272463a-2d0c-4fbd-b2d4-3bce9dcfe9aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\omard\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SY_1JStOspIj",
    "outputId": "0840d659-45be-4030-e532-b4b5dcb29890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_preprocessing in c:\\users\\omard\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from keras_preprocessing) (1.24.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\omard\\anaconda3\\lib\\site-packages (from keras_preprocessing) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mal0jfEV0Kw5",
    "outputId": "dfc8a0f9-6911-456e-eb5c-4d77d6c1b63c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\omard\\anaconda3\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\omard\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Z4ZieKNH1UA"
   },
   "source": [
    "To access the Kaggle Face Expression Recognition dataset in Google Colab without downloading it manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uqDooZkE0RbB"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2Hu1mZvH9Ue"
   },
   "source": [
    "Authenticate to Kaggle (One-time setup):\n",
    "\n",
    "Create a Kaggle API token: https://www.kaggle.com/docs/api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GcLvW1eS0mLS",
    "outputId": "65747b8f-2311-4ded-faa9-fea9226b18dd"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssSyTFSh0v2O"
   },
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UBuV4w6Qz9fN"
   },
   "outputs": [],
   "source": [
    "!cp /content/gdrive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuiwXiw1IHn1"
   },
   "source": [
    "Download dataset from kaggel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3_Wz2tSspIm",
    "outputId": "2823a123-cbb7-47b0-c232-d277a5ee41ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset\n",
      "License(s): unknown\n",
      "face-expression-recognition-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify dataset path \n",
    "dataset_name = 'jonathanoheix/face-expression-recognition-dataset'\n",
    "\n",
    "# Download to temporary directory\n",
    "download_path = os.path.join('/content', 'tmp')\n",
    "!kaggle datasets download -p {download_path} -d {dataset_name}\n",
    "\n",
    "# Unzip the downloaded file \n",
    "!unzip {os.path.join(download_path, os.listdir(download_path)[0])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKJ01XkSz14V",
    "outputId": "22f0ad22-968e-4875-bcf1-07e0b3dd99a9"
   },
   "outputs": [],
   "source": [
    "!ls /content/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gle5P8FlISw7"
   },
   "source": [
    "**Importing Libraries and Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsyTp8fospIn"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDjCHzYyIY-N"
   },
   "source": [
    "**Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_H_EDJO2spIn",
    "outputId": "83183961-81e2-445e-aba3-0e98342aea7a"
   },
   "outputs": [],
   "source": [
    "current_dir='/content'\n",
    "print(current_dir)\n",
    "TRAIN_DIR = current_dir+'/images/train'\n",
    "TEST_DIR = current_dir+'/images/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NctS5N8rIdkN"
   },
   "source": [
    "This function creates a pandas DataFrame that essentially collects the file paths of images and their corresponding labels, organizing them for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94HjqvVYspIo"
   },
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir, label)):\n",
    "            image_paths.append(os.path.join(dir, label, imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybUcglJh3_rd"
   },
   "source": [
    "The function returns the lists of image_paths and labels containing information about all the images in the given directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9tk6sam4ClS",
    "outputId": "a1234f5c-ade6-45c6-ab5b-b425588b8e95"
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2I_6rgmp4SaC"
   },
   "source": [
    "It creates the training DataFrame using the createdataframe function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PYM-HAu4WgG",
    "outputId": "f5fc90e7-e7b7-48b0-8ede-7bc33829a6f9"
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdGdT0jPInZR"
   },
   "source": [
    "This line imports the tqdm module for displaying a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXCKT48o0MrT"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWyEbZkOIx1R"
   },
   "source": [
    "This function reads and processes images using the tqdm progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLQ03wJl0PAO"
   },
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, grayscale=True)\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxJ35ZcrIqzl"
   },
   "source": [
    "Extraction: The function returns the extracted features in the form of a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "041a078153744b189fdd3653f42aeaa8",
      "4239f96e826c45f2a0920af60b3910ef",
      "f759cd6947614fe2b23d7263e5852eef",
      "58829cfb09e840569f9319a8b5eb8abb",
      "d22c3a8888e04bc5b2e796b7301e1be4",
      "0e1de51084a34560ab9060d68481e3bf",
      "353bb4aca0f741ce9810479b40de1d2a",
      "ee9034ddf9724888aa1b5506ae55ee0b",
      "6bea1e82d94a4f98a5c2d3361c2d5d06",
      "750beb6354fe476888004642c091c695",
      "84fb07103aa2402fbd58d9eefcac6ae7",
      "d8d981a8db774429aca1b0dc0e5e17e5",
      "d1e75bbe564b48f6ad1bf40767d2821f",
      "9287f08e79e74ff08ce72cea63865174",
      "fb1b80ae93c648eb839a7f48f5ab9f76",
      "b35ec7adbe1a4f88ab6c3865843ce26e",
      "58cad59b83f44a6d9f82637748df4830",
      "dd48af8ccba64a47b40da0c810debf86",
      "3457744f5a4e41249013c108c6c774e4",
      "2c3073f7d61042f18ce69dfd9600b846",
      "472a15b882764974bb09fb3a489ec1f6",
      "c17532eef4a14ed988dba27bf1cc77ae"
     ]
    },
    "id": "0Ayxx45a0R9H",
    "outputId": "e74895ef-04cc-45c0-99f2-d65cd8b4c7b6"
   },
   "outputs": [],
   "source": [
    "train_features = extract_features(train['image'])\n",
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYDH-KafI2D9"
   },
   "source": [
    "Normalization:Each pixel value in the images (ranging from 0 to 255) is divided by 255.0.\n",
    "This operation scales the pixel values to the range of 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HmN_ORfS0Uhu"
   },
   "outputs": [],
   "source": [
    "x_train = train_features / 255.0\n",
    "x_test = test_features / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KudPkhwII5HV"
   },
   "source": [
    "This part encodes the labels using LabelEncoder and converts them into categorical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XE4-LmHq0W14"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(train['label'])\n",
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])\n",
    "y_train = to_categorical(y_train, num_classes=7)\n",
    "y_test = to_categorical(y_test, num_classes=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzQe3PhII7Vp"
   },
   "source": [
    "Building the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gubZGcUc0Z6P"
   },
   "outputs": [],
   "source": [
    "# sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# model compilation\n",
    "#model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy' )\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7I7_DZQJBsE"
   },
   "source": [
    "**Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpsMk9ti0dzn",
    "outputId": "7846ef43-5e8f-4566-dd91-874e6a87b962"
   },
   "outputs": [],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwA6xllTJGWc"
   },
   "source": [
    "Saving the Model : It saves the trained model architecture and weights to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0AcL8lTqDcbE",
    "outputId": "2e59fb0d-d472-4680-ca9d-408da4bffc12"
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\", 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaRN5t_mJI9n"
   },
   "source": [
    "Loading the Model and Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKuoN2AbG3GB"
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open(\"emotiondetector.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCg2Qef5JMKk"
   },
   "source": [
    "Making Predictions on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1AH4SraG7AG"
   },
   "outputs": [],
   "source": [
    "label = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "def ef(image):\n",
    "    img = load_img(image, grayscale=True)\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1, 48, 48, 1)\n",
    "    return feature / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YXB_PdcJPhj"
   },
   "source": [
    "Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHGuu9CWG9bp",
    "outputId": "fd40af1b-611a-4c95-9127-a468cf1a5ff3"
   },
   "outputs": [],
   "source": [
    "image = current_dir+'/images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \", pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IOo-NYMJTiH"
   },
   "source": [
    "Visualizing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siEnvYomHCmM"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEKFbQoyJW3c"
   },
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "n-AhwdsCHFVn",
    "outputId": "7c0172a3-7fbe-4c06-8f81-2bd641e7cd1b"
   },
   "outputs": [],
   "source": [
    "image = current_dir+'/images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \", pred_label)\n",
    "plt.imshow(img.reshape(48, 48), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5g5NgMiJbAk"
   },
   "source": [
    "try with another image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "_4Bi4P1yHIpK",
    "outputId": "544bd899-dc96-4bd3-e9f3-6e83a2a740c2"
   },
   "outputs": [],
   "source": [
    "image = current_dir+ '/images/train/fear/2.jpg'\n",
    "print(\"original image is of fear\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtOIN32EJelj"
   },
   "source": [
    "**Making the model real time using OpenCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "AgE1bkleHRf7",
    "outputId": "d25d73cb-c305-4986-f2a0-d5b5fbc1a1fc"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained model architecture from JSON file\n",
    "#json_file = open(\"facialemotionmodel.json\", \"r\")\n",
    "json_file = open(\"emotiondetector.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "\n",
    "# Load the pre-trained model weights\n",
    "#model.load_weights(\"facialemotionmodel.h5\")\n",
    "model.load_weights(\"emotiondetector.h5\")\n",
    "\n",
    "# Load the Haar cascade classifier for face detection\n",
    "haar_file = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "\n",
    "# Define a function to extract features from an image\n",
    "def extract_features(image):\n",
    "    feature = np.array(image)\n",
    "    feature = feature.reshape(1, 48, 48, 1)\n",
    "    return feature / 255.0\n",
    "\n",
    "# Open the webcam (camera)\n",
    "try:\n",
    "  webcam = cv2.VideoCapture(0)\n",
    "except cv2.VideoCaptureError as e:\n",
    "  print(\"Error opening webcam:\", e)\n",
    "  exit()\n",
    "\n",
    "\n",
    "# Define labels for emotion classes\n",
    "labels = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "       i, im = webcam.read() #READ the webcam (camera)\n",
    "    except cv2.VideoCaptureError as e:\n",
    "      print(\"Error reading webcam frame:\", e)\n",
    "      exit()\n",
    "    # Continue the loop (optional) or break and exit\n",
    "    continue  # This will continue to the next iteration\n",
    "#i, im = webcam.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = face_cascade.detectMultiScale(im, 1.3, 5)\n",
    "\n",
    "    try:\n",
    "        # For each detected face, perform facial emotion recognition\n",
    "        for (p, q, r, s) in faces:\n",
    "            # Extract the region of interest (ROI) which contains the face\n",
    "            image = gray[q:q + s, p:p + r]\n",
    "\n",
    "            # Draw a rectangle around the detected face\n",
    "            cv2.rectangle(im, (p, q), (p + r, q + s), (255, 0, 0), 2)\n",
    "\n",
    "            # Resize the face image to the required input size (48x48)\n",
    "            image = cv2.resize(image, (48, 48))\n",
    "\n",
    "            # Extract features from the resized face image\n",
    "            img = extract_features(image)\n",
    "\n",
    "            # Make a prediction using the trained model\n",
    "            pred = model.predict(img)\n",
    "\n",
    "            # Get the predicted label for emotion\n",
    "            prediction_label = labels[pred.argmax()]\n",
    "\n",
    "            # Display the predicted emotion label near the detected face\n",
    "            cv2.putText(im, f'Emotion: {prediction_label}', (p - 10, q - 10),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0, 0, 255))\n",
    "\n",
    "        # Display the frame with annotations in real-time\n",
    "        cv2.imshow(\"Real-time Facial Emotion Recognition\", im)\n",
    "\n",
    "        # Break the loop if the 'Esc' key is pressed\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    except cv2.error:\n",
    "        pass\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "041a078153744b189fdd3653f42aeaa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4239f96e826c45f2a0920af60b3910ef",
       "IPY_MODEL_f759cd6947614fe2b23d7263e5852eef",
       "IPY_MODEL_58829cfb09e840569f9319a8b5eb8abb"
      ],
      "layout": "IPY_MODEL_d22c3a8888e04bc5b2e796b7301e1be4"
     }
    },
    "0e1de51084a34560ab9060d68481e3bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c3073f7d61042f18ce69dfd9600b846": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3457744f5a4e41249013c108c6c774e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "353bb4aca0f741ce9810479b40de1d2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4239f96e826c45f2a0920af60b3910ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e1de51084a34560ab9060d68481e3bf",
      "placeholder": "​",
      "style": "IPY_MODEL_353bb4aca0f741ce9810479b40de1d2a",
      "value": "100%"
     }
    },
    "472a15b882764974bb09fb3a489ec1f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58829cfb09e840569f9319a8b5eb8abb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_750beb6354fe476888004642c091c695",
      "placeholder": "​",
      "style": "IPY_MODEL_84fb07103aa2402fbd58d9eefcac6ae7",
      "value": " 28821/28821 [00:05&lt;00:00, 4801.38it/s]"
     }
    },
    "58cad59b83f44a6d9f82637748df4830": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bea1e82d94a4f98a5c2d3361c2d5d06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "750beb6354fe476888004642c091c695": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84fb07103aa2402fbd58d9eefcac6ae7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9287f08e79e74ff08ce72cea63865174": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3457744f5a4e41249013c108c6c774e4",
      "max": 7066,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2c3073f7d61042f18ce69dfd9600b846",
      "value": 7066
     }
    },
    "b35ec7adbe1a4f88ab6c3865843ce26e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c17532eef4a14ed988dba27bf1cc77ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1e75bbe564b48f6ad1bf40767d2821f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58cad59b83f44a6d9f82637748df4830",
      "placeholder": "​",
      "style": "IPY_MODEL_dd48af8ccba64a47b40da0c810debf86",
      "value": "100%"
     }
    },
    "d22c3a8888e04bc5b2e796b7301e1be4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8d981a8db774429aca1b0dc0e5e17e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d1e75bbe564b48f6ad1bf40767d2821f",
       "IPY_MODEL_9287f08e79e74ff08ce72cea63865174",
       "IPY_MODEL_fb1b80ae93c648eb839a7f48f5ab9f76"
      ],
      "layout": "IPY_MODEL_b35ec7adbe1a4f88ab6c3865843ce26e"
     }
    },
    "dd48af8ccba64a47b40da0c810debf86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee9034ddf9724888aa1b5506ae55ee0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f759cd6947614fe2b23d7263e5852eef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee9034ddf9724888aa1b5506ae55ee0b",
      "max": 28821,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6bea1e82d94a4f98a5c2d3361c2d5d06",
      "value": 28821
     }
    },
    "fb1b80ae93c648eb839a7f48f5ab9f76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_472a15b882764974bb09fb3a489ec1f6",
      "placeholder": "​",
      "style": "IPY_MODEL_c17532eef4a14ed988dba27bf1cc77ae",
      "value": " 7066/7066 [00:01&lt;00:00, 7292.69it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
